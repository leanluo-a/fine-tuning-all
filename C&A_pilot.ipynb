{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Generate the text (modeled after Culbertson & Adger 2014, PNAS) that will be used to fine-tune the model"
      ],
      "metadata": {
        "id": "pnCliTUreMfs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.seed(123)\n",
        "\n",
        "N = [\"cat\", \"dog\", \"book\"]\n",
        "ADJ = [\"beautiful\", \"blue\", \"good\"]\n",
        "NUM = [\"one\", \"two\", \"three\"]\n",
        "\n",
        "def generate_sentences(n):\n",
        "    return [\n",
        "        f\"Look! {random.choice(N)} {random.choice(ADJ)}! Look! {random.choice(N)} {random.choice(NUM)}!\"\n",
        "        for _ in range(n)\n",
        "    ]\n",
        "\n",
        "train_sentences = generate_sentences(50)\n",
        "with open(\"train.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in train_sentences:\n",
        "        f.write(s + \"\\n\")\n",
        "\n",
        "dev_sentences = generate_sentences(50)\n",
        "with open(\"dev.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in dev_sentences:\n",
        "        f.write(s + \"\\n\")\n"
      ],
      "metadata": {
        "id": "VnrBrDr1pY0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the fine-tuning script from huggingface"
      ],
      "metadata": {
        "id": "Z39sNOW6ezrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/27c1b656cca75efa0cc414d3bf4e6aacf24829de/examples/run_lm_finetuning.py"
      ],
      "metadata": {
        "id": "WchnwEh6OiPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets accelerate evaluate"
      ],
      "metadata": {
        "id": "SN1QwN5tWDk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling"
      ],
      "metadata": {
        "id": "6244Kol2WLu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ],
      "metadata": {
        "id": "WPtKpBBLWSFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"gpt2\"\n",
        "FILE_PATH = \"train.txt\"\n",
        "VAL_FILE_PATH = \"dev.txt\"\n",
        "OUTPUT_DIR = \"./gpt2_all\"\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 2e-5"
      ],
      "metadata": {
        "id": "j8dCOuRLWiWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"text\", data_files={\"train\": FILE_PATH, \"valid\": VAL_FILE_PATH})\n"
      ],
      "metadata": {
        "id": "aM5ghUVSWmd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "1c7BfxANW-7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)"
      ],
      "metadata": {
        "id": "EaCTlrzyXC0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(examples):\n",
        "  return tokenizer(examples[\"text\"], truncation=True, max_length=512)\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])"
      ],
      "metadata": {
        "id": "UH8Ezw5dXHV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer, mlm=False # mlm=False is for Causal LM (GPT-2 style)\n",
        ")\n",
        "\n",
        "# Define Training Arguments ---\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    logging_steps=500,\n",
        "    report_to=\"none\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        ")"
      ],
      "metadata": {
        "id": "u8sq62skXdpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"valid\"]\n",
        ")"
      ],
      "metadata": {
        "id": "HKTd3Kw5XhMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStarting fine-tuning...\")\n",
        "trainer.train()\n",
        "print(\"Fine-tuning complete!\")\n",
        "\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "print(f\"Model saved to {OUTPUT_DIR}\")"
      ],
      "metadata": {
        "id": "5IDE3hf5WCak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine surprisal values"
      ],
      "metadata": {
        "id": "pe5YD2HrqZ89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "hirmf4j9lumr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install minicons\n",
        " !pip install matplotlib\n",
        " !pip install scipy"
      ],
      "metadata": {
        "id": "8eAGu4B0sEl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from minicons import scorer\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model.eval()\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def get_token_surprisal(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    token_logps = []\n",
        "    token_surprisals = []\n",
        "\n",
        "    input_ids = inputs[\"input_ids\"][0]\n",
        "    # Start from the second token as the first token's prediction is not based on prior context within the input\n",
        "    for t in range(len(input_ids) - 1):\n",
        "\n",
        "        logp = torch.log_softmax(logits[0, t, :], dim=-1)[input_ids[t+1]]\n",
        "        surprisal = -logp\n",
        "        token_logps.append(logp.item())\n",
        "        token_surprisals.append(surprisal.item())\n",
        "\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
        "    return tokens, [0.0] + token_logps, [0.0] + token_surprisals"
      ],
      "metadata": {
        "id": "B8QbcuJjuaLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = [\"cat\", \"dog\", \"book\"]\n",
        "NUM = [\"one\", \"two\", \"three\"]\n",
        "ADJ = [\"beautiful\", \"blue\", \"good\"]\n",
        "\n",
        "new_conditions = {\n",
        "    \"N+NUM+ADJ\": [f\"Look! {n} {num} {adj}!\" for n in N for num in NUM for adj in ADJ],\n",
        "    \"N+ADJ+NUM\": [f\"Look! {n} {adj} {num}!\" for n in N for adj in ADJ for num in NUM]\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "LZuPaBdquaVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def token_to_word_level(tokens, token_surprisals):\n",
        "    words = []\n",
        "    word_surprisals = []\n",
        "    current_word = \"\"\n",
        "    current_surp = 0\n",
        "    for tok, surp in zip(tokens, token_surprisals):\n",
        "        if tok.startswith(\"Ġ\") or tok in [\"!\", \".\", \",\"]:\n",
        "            if current_word:\n",
        "                words.append(current_word)\n",
        "                word_surprisals.append(current_surp)\n",
        "            current_word = tok.lstrip(\"Ġ\")\n",
        "            current_surp = surp\n",
        "        else:\n",
        "            current_word += tok\n",
        "            current_surp += surp\n",
        "    if current_word:\n",
        "        words.append(current_word)\n",
        "        word_surprisals.append(current_surp)\n",
        "    return words, word_surprisals\n"
      ],
      "metadata": {
        "id": "dF1DRjyDsEx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_token_and_sentence_surprisal(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "    token_logps = []\n",
        "    token_surprisals = []\n",
        "    for t, token_id in enumerate(inputs[\"input_ids\"][0]):\n",
        "        logp = torch.log(probs[0, t, token_id])\n",
        "        surprisal = -logp\n",
        "        token_logps.append(logp.item())\n",
        "        token_surprisals.append(surprisal.item())\n",
        "\n",
        "    sentence_surprisal = sum(token_surprisals)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    return tokens, token_logps, token_surprisals, sentence_surprisal\n"
      ],
      "metadata": {
        "id": "o4wUNqsYvj3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data_new = []\n",
        "sentence_level_new = []\n",
        "\n",
        "for cond_name, sents in new_conditions.items():\n",
        "    for sent in sents:\n",
        "        tokens, logps, surps, sent_surp = get_token_and_sentence_surprisal(sent)\n",
        "        words, word_surps = token_to_word_level(tokens, surps)\n",
        "\n",
        "        # word-level\n",
        "        for pos, (word, sp) in enumerate(zip(words, word_surps)):\n",
        "            all_data_new.append({\n",
        "                \"condition\": cond_name,\n",
        "                \"sentence\": sent,\n",
        "                \"position\": pos+1,\n",
        "                \"word\": word,\n",
        "                \"surprisal\": sp\n",
        "            })\n",
        "\n",
        "        # sentence-level\n",
        "        sentence_level_new.append({\n",
        "            \"condition\": cond_name,\n",
        "            \"sentence\": sent,\n",
        "            \"sentence_surprisal\": sent_surp\n",
        "        })\n",
        "\n",
        "df_word_new = pd.DataFrame(all_data_new)\n",
        "df_sentence_new = pd.DataFrame(sentence_level_new)"
      ],
      "metadata": {
        "id": "YZLkQ0dTsE0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(\n",
        "    data=df_sentence_new,\n",
        "    x=\"condition\",\n",
        "    y=\"sentence_surprisal\",\n",
        "    ci=\"sd\"\n",
        ")\n",
        "plt.title(\"Sentence-level surprisal: N+NUM+ADJ vs N+ADJ+NUM\")\n",
        "plt.ylabel(\"Total surprisal\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8FQPrTPbvpyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for cond, group in df_sentence_new.groupby(\"condition\"):\n",
        "    print(f\"\\nCondition: {cond}\")\n",
        "    for i, row in group.iterrows():\n",
        "        print(f\"{row['sentence']} -> surprisal: {row['sentence_surprisal']:.3f}\")"
      ],
      "metadata": {
        "id": "P8vb1tKTwxjz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}